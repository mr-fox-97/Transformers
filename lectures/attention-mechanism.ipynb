{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El concepto de key/value/query es análogo a los sistemas de busqueda. Por ejemplo, cuando busca videos en Youtube, el motor de búsqueda asigna su consulta (query) (texto en la barra de búsqueda) contra un conjunto de claves (keys) (título del video, descripción, etc.) asociadas con videos candidatos en su base de datos, y luego le presenta los con mayor coincidencia (values).\n",
    "\n",
    "Para los modelos de lenguage, los key/value/query generalemente provienen de la misma fuente, es por esto que se denomina mecanismo de self-attention (atencion propia).\n",
    "\n",
    "La entrada consta de consultas y claves de dimensión $d_k$, y valores de dimensión $d_v$.\n",
    "\n",
    "$$ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from torch import Tensor\n",
    "from torch import matmul\n",
    "from torch.nn import Module\n",
    "from torch.nn import Linear, Dropout\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "class MultiheadAttention(Module):\n",
    "    def __init__(self, model_dimension: int, number_of_heads: int, dropout_rate: float):\n",
    "        super().__init__()\n",
    "        self.number_of_heads = number_of_heads\n",
    "\n",
    "        self.key_projector = Linear(model_dimension, model_dimension, bias=False)\n",
    "        self.value_projector = Linear(model_dimension, model_dimension, bias=False)\n",
    "        self.query_projector = Linear(model_dimension, model_dimension, bias=False)\n",
    "        self.output_projector = Linear(model_dimension, model_dimension, bias=False)\n",
    "\n",
    "        self.dropout = Dropout(p=dropout_rate)\n",
    "        self.mask = None\n",
    "        \n",
    "    def split(self, tensor: Tensor) -> Tensor:\n",
    "        batch_size, sequence_lenght, model_dimension = tensor.size()\n",
    "        tensor_dimension = model_dimension // self.number_of_heads\n",
    "        return tensor.view(batch_size, sequence_lenght, self.number_of_heads, tensor_dimension).transpose(1, 2)\n",
    "    \n",
    "    def concatenate(self, tensor: Tensor) -> Tensor: \n",
    "        batch_size, number_of_heads, sequence_lenght, tensor_dimension = tensor.size()\n",
    "        model_dimension = number_of_heads * tensor_dimension\n",
    "        return tensor.transpose(1, 2).contiguous().view(batch_size, sequence_lenght, model_dimension)\n",
    "\n",
    "    def attention(self, key: Tensor, query: Tensor, value: Tensor) -> Tensor:\n",
    "        scale = sqrt(key.size(-1))\n",
    "        score = (query @ key.transpose(-2, -1) ) / scale\n",
    "        if self.mask:\n",
    "            score = score.masked_fill(self.mask, float('-inf'))\n",
    "        return softmax(score, dim=-1) @ value\n",
    "    \n",
    "    def forward(self, key: Tensor, query: Tensor, value: Tensor) -> Tensor:\n",
    "        key, query, value = self.key_projector(key), self.query_projector(query), self.value_projector(value)\n",
    "        key, query, value = self.split(key), self.split(query), self.split(value)\n",
    "        attention = self.attention(key, query, value)\n",
    "        attention = self.dropout(attention)\n",
    "        attention = self.concatenate(attention)\n",
    "        output = self.output_projector(attention)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
